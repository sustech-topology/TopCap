{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os # read system path \n",
    "import csv\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from gudhi.point_cloud import timedelay\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import math\n",
    "from ripser import ripser\n",
    "%matplotlib qt5\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function define\n",
    "\n",
    "# principle_frequency_finder is to find the period of a speech signal\n",
    "def principle_frequency_finder(sig):\n",
    "    t=int(len(sig)/2)\n",
    "    corr=np.zeros(t)\n",
    "\n",
    "    for index in np.arange(t):\n",
    "        ACF_delay=sig[index:]\n",
    "        L=(t-index)/2\n",
    "        m = np.sum(sig[int(t-L):int(t+L+1)]**2) + np.sum(ACF_delay[int(t-L):int(t+L+1)]**2)\n",
    "        r = np.sum(sig[int(t-L):int(t+L+1)]*ACF_delay[int(t-L):int(t+L+1)])\n",
    "        corr[index] = 2*r/m\n",
    "\n",
    "    zc = np.zeros(corr.size-1)\n",
    "    zc[(corr[0:-1] < 0)*(corr[1::] > 0)] = 1\n",
    "    zc[(corr[0:-1] > 0)*(corr[1::] < 0)] = -1\n",
    "\n",
    "    admiss = np.zeros(corr.size)\n",
    "    admiss[0:-1] = zc\n",
    "    for i in range(1, corr.size):\n",
    "        if admiss[i] == 0:\n",
    "            admiss[i] = admiss[i-1]\n",
    "\n",
    "    maxes = np.zeros(corr.size)\n",
    "    maxes[1:-1] = (np.sign(corr[1:-1] - corr[0:-2])==1)*(np.sign(corr[1:-1] - corr[2::])==1)\n",
    "    maxidx = np.arange(corr.size)\n",
    "    maxidx = maxidx[maxes == 1]\n",
    "    max_index = 0\n",
    "    if len(corr[maxidx]) > 0:\n",
    "        max_index = maxidx[np.argmax(corr[maxidx])]\n",
    "\n",
    "    return (max_index, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f928859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path is where the voiced/voicedless wav file located\n",
    "voicedPath=\"..\"\n",
    "voicedlessPath=\"..\"\n",
    "\n",
    "# Parameter for embedding\n",
    "M=100 # embed dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d082580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive features from persistent diagram \n",
    "# For voiced data\n",
    "for fn in os.listdir(voicedPath):\n",
    "    # Subsample dataset, retrieve 1 in 10 among dataset\n",
    "    randNum=np.random.randint(10)\n",
    "    if randNum !=0:\n",
    "        continue\n",
    "\n",
    "    # Read wav file as \"sig\"\n",
    "    fileName,ext=os.path.splitext(fn)\n",
    "    wavFile=voicedPath+fileName+\".wav\"\n",
    "    sig,samplerate=sf.read(wavFile)\n",
    "    \n",
    "    # Find the principle frequency, delay of sig\n",
    "    T_voiced,corr=principle_frequency_finder(sig)\n",
    "    delay_voiced=round(T_voiced*6/M)\n",
    "    if delay_voiced==0:\n",
    "        delay_voiced=1\n",
    "\n",
    "    if delay_voiced*M>len(sig):\n",
    "        delay_voiced=int(np.floor(len(sig)/M))\n",
    "\n",
    "    # Write result in a csv file\n",
    "    with open(\"Persistent_Diag.csv\",\"a\",newline=\"\") as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "\n",
    "        # Time-delay embedding of voiced data\n",
    "        point_Cloud=timedelay.TimeDelayEmbedding(M, delay_voiced, 5)\n",
    "        Points=point_Cloud(sig)\n",
    "        if len(Points)<40:               \n",
    "            continue\n",
    "        \n",
    "        # Compute persistent diagram of piont cloud\n",
    "        dgms = ripser(Points,maxdim=1)['dgms']\n",
    "        dgms=dgms[1]\n",
    "        if dgms.size==0:\n",
    "            continue\n",
    "        persistent_time=[ele[1]-ele[0] for ele in dgms]            \n",
    "        index=argmax(persistent_time)\n",
    "\n",
    "        # Compute birth time and lifetime \n",
    "        # Write them into csv file\n",
    "        # 0 indicate voiced data\n",
    "        birth_date=dgms[index][0]\n",
    "        lifetime=persistent_time[index]\n",
    "        writer.writerow((birth_date,lifetime,0))\n",
    "        \n",
    "\n",
    "# For voicedless data\n",
    "\n",
    "for fn in os.listdir(voicedlessPath):\n",
    "    # Subsample dataset, retrieve 1 in 10 among dataset\n",
    "    randNum=np.random.randint(10)\n",
    "    if randNum !=0:\n",
    "        continue\n",
    "    \n",
    "    # Read wav file as \"sig\"\n",
    "    fileName,ext=os.path.splitext(fn)\n",
    "    wavFile=voicedlessPath+fileName+\".wav\"\n",
    "    sig,samplerate=sf.read(wavFile)\n",
    "    \n",
    "    # Find the principle frequency, delay of sig\n",
    "    T_voicedless,corr=principle_frequency_finder(sig)\n",
    "    delay_voicedless=round(T_voicedless*6/M)\n",
    "    if delay_voicedless==0:\n",
    "        delay_voicedless=1\n",
    "\n",
    "    if delay_voicedless*M>len(sig):\n",
    "        delay_voicedless=int(np.floor(len(sig)/M))\n",
    "\n",
    "    # Write result in a csv file\n",
    "    with open(\"Persistent_Diag.csv\",\"a\",newline=\"\") as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "\n",
    "        # Time-delay embedding of voiced data\n",
    "        point_Cloud=timedelay.TimeDelayEmbedding(M, delay_voicedless, 5)\n",
    "        Points=point_Cloud(sig)\n",
    "        if len(Points)<40:               \n",
    "            continue\n",
    "        \n",
    "        # Compute persistent diagram of piont cloud\n",
    "        dgms = ripser(Points,maxdim=1)['dgms']\n",
    "        dgms=dgms[1]\n",
    "        if dgms.size==0:\n",
    "            continue\n",
    "        persistent_time=[ele[1]-ele[0] for ele in dgms]            \n",
    "        index=argmax(persistent_time)\n",
    "\n",
    "        # Compute birth time and lifetime \n",
    "        # Write them into csv file\n",
    "        # 1 indicate voicedless data\n",
    "        birth_date=dgms[index][0]\n",
    "        lifetime=persistent_time[index]\n",
    "        writer.writerow((birth_date,lifetime,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eaf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into DataFrame\n",
    "df=pd.read_csv('Persistent_Diag.csv', names=['birth_date','lifetime','type'],header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27672040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle 9000 samples for each voice and voiceless type\n",
    "\n",
    "# Shuffle 9000 rows from each class\n",
    "df_0 = df[df['type'] == 0].sample(n=9000, random_state=42)\n",
    "df_1 = df[df['type'] == 1].sample(n=9000, random_state=42)\n",
    "\n",
    "# Combine and shuffle again (optional)\n",
    "df_feature = pd.concat([df_0, df_1]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c546ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization: min-max\n",
    "normalized_df=(df_feature[['birth_date','lifetime']]-df_feature[['birth_date','lifetime']].min())/(df_feature[['birth_date','lifetime']].max()-df_feature[['birth_date','lifetime']].min())\n",
    "normalized_df['type']=df_feature['type']\n",
    "\n",
    "# Read/load data if needed\n",
    "#normalized_df.to_pickle('topcap_df_feature_normalized')\n",
    "#normalized_df=pd.read_pickle('topcap_df_feature_normalized')\n",
    "\n",
    "# Check the number of samples in each class\n",
    "(normalized_df['type']==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22995310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalized result\n",
    "# Set up plot configuration\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "\n",
    "# Group the data based on voiced/ voicedless\n",
    "groups = normalized_df.groupby('type')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.margins(0.05)\n",
    "typeDict= {1:'voicedless',0:'voiced'}\n",
    "for type, group in groups:\n",
    "    if type==1:\n",
    "        ax.plot(group.birth_date, group.lifetime, marker='o', linestyle='', ms=2, label=typeDict[type],alpha=0.5, color='#4d4dff')\n",
    "    if type==0:\n",
    "        ax.plot(group.birth_date, group.lifetime, marker='o', linestyle='', ms=2, label=typeDict[type],alpha=0.5, color='#ff5c33')\n",
    "legend=ax.legend(fontsize=15,markerscale=4)\n",
    "plt.xlabel('Birth Time')\n",
    "plt.ylabel('Lifetime')\n",
    "\n",
    "## Save figure as pdf file\n",
    "#plt.savefig(\"..\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual \n",
    "plt.figure(figsize=(6, 3))\n",
    "\n",
    "for type, group in groups:\n",
    "    if type==0:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(group.birth_date, group.lifetime, marker='o', linestyle='', ms=2, label=typeDict[type], alpha=0.5, color='#ff5c33')\n",
    "        plt.legend(['voiced'],fontsize=10,markerscale=4,loc='upper right')\n",
    "        plt.xlabel('Birth Time')\n",
    "        plt.ylabel('Lifetime')\n",
    "        plt.xlim([-0.1,1.1])\n",
    "        plt.ylim([-0.1,1.1])\n",
    "        plt\n",
    "    if type==1:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(group.birth_date, group.lifetime, marker='o', linestyle='', ms=2, label=typeDict[type], alpha=0.5, color='#4d4dff')\n",
    "        plt.legend(['voiceless'],fontsize=10,markerscale=4,loc='upper right')\n",
    "        plt.xlabel('Birth Time')\n",
    "        plt.ylabel('Lifetime')\n",
    "        plt.xlim([-0.1,1.1])\n",
    "        plt.ylim([-0.1,1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Save figure as pdf file\n",
    "#plt.savefig(\"..\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26320fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_df[['birth_date','lifetime']], normalized_df['type'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict class labels for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
